{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Wb_l_xlfb1L",
        "outputId": "4d2ee9ed-11ac-479c-e53f-9dff2c414536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CV-Parsing-using-Spacy-3'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 82 (delta 14), reused 74 (delta 14), pack-reused 6\u001b[K\n",
            "Receiving objects: 100% (82/82), 5.62 MiB | 27.00 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/laxmimerit/CV-Parsing-using-Spacy-3.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy_transformers\n",
        "!pip install -U spacy"
      ],
      "metadata": {
        "id": "zZxCFLOUfvv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3655c3-a7f2-49db-d3c3-da0d076a213a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy_transformers\n",
            "  Downloading spacy_transformers-1.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (197 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/197.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m194.6/197.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.9/197.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (3.7.4)\n",
            "Collecting transformers<4.37.0,>=3.4.0 (from spacy_transformers)\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (2.4.8)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy_transformers)\n",
            "  Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (1.25.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.1.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy_transformers) (1.3.0)\n",
            "Installing collected packages: spacy-alignments, transformers, spacy_transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.1\n",
            "    Uninstalling transformers-4.38.1:\n",
            "      Successfully uninstalled transformers-4.38.1\n",
            "Successfully installed spacy-alignments-0.9.1 spacy_transformers-1.3.4 transformers-4.36.2\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json"
      ],
      "metadata": {
        "id": "IYX94wn_gvbQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MZXoGa-Kg4_B",
        "outputId": "f1689d58-fd80-411b-c714-6a5a5e8a769d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data=json.load(open('/content/CV-Parsing-using-Spacy-3/data/training/train_data.json','r'))"
      ],
      "metadata": {
        "id": "Z7sBjzXZhQYS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(cv_data)\n",
        "cv_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHNejOYDh6YK",
        "outputId": "314c30aa-528f-432c-9c8e-299b32c4fde4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [[1749, 1755, 'Companies worked at'],\n",
              "   [1696, 1702, 'Companies worked at'],\n",
              "   [1417, 1423, 'Companies worked at'],\n",
              "   [1356, 1793, 'Skills'],\n",
              "   [1209, 1215, 'Companies worked at'],\n",
              "   [1136, 1247, 'Skills'],\n",
              "   [928, 932, 'Graduation Year'],\n",
              "   [858, 889, 'College Name'],\n",
              "   [821, 856, 'Degree'],\n",
              "   [787, 791, 'Graduation Year'],\n",
              "   [744, 750, 'Companies worked at'],\n",
              "   [722, 742, 'Designation'],\n",
              "   [658, 664, 'Companies worked at'],\n",
              "   [640, 656, 'Designation'],\n",
              "   [574, 580, 'Companies worked at'],\n",
              "   [555, 572, 'Designation'],\n",
              "   [470, 493, 'Companies worked at'],\n",
              "   [444, 468, 'Designation'],\n",
              "   [308, 314, 'Companies worked at'],\n",
              "   [234, 240, 'Companies worked at'],\n",
              "   [175, 198, 'Companies worked at'],\n",
              "   [93, 136, 'Email Address'],\n",
              "   [39, 48, 'Location'],\n",
              "   [13, 37, 'Designation'],\n",
              "   [0, 12, 'Name']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config /content/CV-Parsing-using-Spacy-3/data/training/base_config.cfg /content/CV-Parsing-using-Spacy-3/data/training/config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht8ZSN_qh78l",
        "outputId": "a231150b-0413-4479-b08b-ff553ef6d412"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/CV-Parsing-using-Spacy-3/data/training/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spacy_doc(file,data):\n",
        "  nlp=spacy.blank('en')\n",
        "  db=DocBin()\n",
        "  for text,annot in tqdm(data):\n",
        "    doc=nlp.make_doc(text)\n",
        "    annot=annot['entities']\n",
        "    ents=[]\n",
        "    entity_indices=[]\n",
        "    for start,end,label in annot:\n",
        "      skip_entity=False\n",
        "      for idx in range(start,end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity=True\n",
        "          break\n",
        "      if skip_entity==True:\n",
        "        continue\n",
        "\n",
        "      entity_indices=entity_indices+list(range(start,end))\n",
        "      try:\n",
        "        span=doc.char_span(start,end,label=label,alignment_mode='strict')\n",
        "      except:\n",
        "        continue\n",
        "      if span is None:\n",
        "        err_data=str([start,end]) + \"   \" +str(text)+\"\\n\"\n",
        "        file.write(err_data)\n",
        "      else:\n",
        "        ents.append(span)\n",
        "    try:\n",
        "      doc.ents=ents\n",
        "      db.add(doc)\n",
        "    except:\n",
        "      pass\n",
        "  return db"
      ],
      "metadata": {
        "id": "1suleBtLit9V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test=train_test_split(cv_data,test_size=0.3)"
      ],
      "metadata": {
        "id": "E_JukTUqm7Vm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train),len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8KGEt5KnO5y",
        "outputId": "14bbfcf5-09e8-484b-e6da-870cf11189b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 60)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file=open('/content/CV-Parsing-using-Spacy-3/data/training/train_data.json','w')\n",
        "db=get_spacy_doc(file,train)\n",
        "db.to_disk('/content/train_data.spacy')\n",
        "db=get_spacy_doc(file,test)\n",
        "db.to_disk('/content/test_data.spacy')\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07h6m0LdnT0S",
        "outputId": "de31bdfc-c379-4a17-a55b-12fd08109643"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140/140 [00:01<00:00, 73.25it/s]\n",
            "100%|██████████| 60/60 [00:00<00:00, 73.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train /content/CV-Parsing-using-Spacy-3/data/training/config.cfg --output /content/output --paths.train /content/train_data.spacy --paths.dev  /content/test_data.spacy  --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPvf5sLPrvUK",
        "outputId": "da5a0605-0c0b-464f-bb17-5cae4ec1926e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: /content/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: /content/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 141kB/s]\n",
            "config.json: 100% 481/481 [00:00<00:00, 2.86MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 67.1MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 1.84MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 2.71MB/s]\n",
            "model.safetensors: 100% 499M/499M [00:08<00:00, 60.3MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        1392.16   1421.41    0.15    0.08    3.27    0.00\n",
            "  4     200      155863.89  66154.07   22.30   48.36   14.49    0.22\n",
            "  8     400       48434.44  23745.95   49.97   50.39   49.56    0.50\n",
            " 12     600       10296.25  20633.11   50.60   52.78   48.58    0.51\n",
            " 17     800        3549.00  19019.31   56.77   54.39   59.37    0.57\n",
            " 21    1000        2006.82  16092.72   51.46   60.12   44.99    0.51\n",
            " 25    1200        3811.69  15643.03   50.85   57.05   45.86    0.51\n",
            " 29    1400       22676.45  15032.24   53.65   55.32   52.07    0.54\n",
            " 34    1600         880.03  14785.83   56.43   51.87   61.87    0.56\n",
            " 38    1800         603.08  13430.77   55.89   59.46   52.72    0.56\n",
            " 42    2000        2123.56  13239.56   53.25   64.11   45.53    0.53\n",
            " 46    2200        1386.22  12967.98   55.22   58.37   52.40    0.55\n",
            " 51    2400       28710.23  13061.63   57.47   55.03   60.13    0.57\n",
            " 55    2600        2314.85  11267.33   56.94   56.91   56.97    0.57\n",
            " 59    2800        9986.71  10887.83   53.78   59.89   48.80    0.54\n",
            " 63    3000         532.43   9995.93   55.91   60.08   52.29    0.56\n",
            " 68    3200         304.85   9222.81   55.01   55.91   54.14    0.55\n",
            " 72    3400         287.85   7655.57   57.27   60.66   54.25    0.57\n",
            " 76    3600         605.60   6661.26   55.20   56.43   54.03    0.55\n",
            " 80    3800        3704.11   5609.94   56.08   58.28   54.03    0.56\n",
            " 85    4000         430.15   4411.88   55.69   59.29   52.51    0.56\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('/content/output/model-best')"
      ],
      "metadata": {
        "id": "6vYvP80G_UHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt='''\n",
        "Keval Savaliya\n",
        "Rajkot, Gujarat, India 360311\n",
        "ć kpsavaliya1gmail.com | Ħ +91 (90) 2353-6905 a keval-savaliya | ] keval-savaliya\n",
        "Education\n",
        "Nirma University, Ahemdabad September. 2021 – Present\n",
        "B.Tech Computer Science And Engineering GPA: 7.95/10\n",
        "Tapovan Science School, Rajkot June. 2019 – April 2021\n",
        "Gujarat Secondary and Higher Secondary Education Board Percentage : 93.53/100\n",
        "Gangotri School, Rajkot, Gondal June 2018 – April 2019\n",
        "Gujarat Secondary Education Board Percentage : 90.83/100\n",
        "Projects\n",
        "Food Delivery Website HTML, CSS, JavaScript\n",
        "• Technology and Frameworks that our team used in this project: Bootstrap, Node.Js, JavaScript, Ejs, Cloudinary,\n",
        "Express.Js, MongoDB.\n",
        "• Online platform for orderning food items.\n",
        "• View Project\n",
        "Music Genre Classification and Recommendation System Python, Sklearn\n",
        "• Take one dataset which contain details of various type of song like roke, pop, etc.Analyse dataset feature, generate\n",
        "some chart for better visualisation.\n",
        "• Make various ML & DL model.Train those model using dataset.\n",
        "• Find best classification Model.Take one input song and our model classify into which type of this song.\n",
        "• View Project\n",
        "GUI Based E-mail System JAVA, AWT Framework, Maven\n",
        "• Created small scale project based on Java. User need to Login Based on their E-mail.\n",
        "• Sending email using Google E-mail Id.Used Java libraries for concepts of Computer.\n",
        "• For Transition of mail we use SMTP protocol.\n",
        "Banking System JAVA\n",
        "• Object Oriented Programming Concepts, CSV file\n",
        "• Cli based application for Banking system using file handling\n",
        "• Create function of banking service like Open a new Account, See Your account details, ATM Service, Withdraw, Deposit\n",
        "and etc.\n",
        "Courses And Technical Skills\n",
        "Languages: Python, C, C++, Java, HTML/CSS/JS, NodeJS, SQL, MongoDB\n",
        "Frameworks: Flask, BootStrap, ReactJS, ExpressJS\n",
        "Certifications:\n",
        "Machine Learning Specialization :\n",
        "• Supervised Machine Learning: Regression and Classification\n",
        "• Advanced Learning Algorithms\n",
        "• Unsupervised Learning, Recommenders, Reinforcement Learning\n",
        "Technologies & Tools:\n",
        "CodeForces : Max Rating 1399\n",
        "CodeChef : Max Rating 1830\n",
        "Hackerrank : Competitive Programming\n",
        "Extracurricular And Volunteering Activities\n",
        "7 Days NSS Camp April 24 - 30, 2022\n",
        "Miroli Village, Ahmedabad\n",
        "• Part of 7 Days residential Camp organized by Nirma University\n",
        "• Took survey about their Health & literacy ratio\n",
        "'''"
      ],
      "metadata": {
        "id": "FV_2_RJv_art"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(txt)\n",
        "for ent in doc.ents:\n",
        "  print(ent.label_ ,\"  --->>>>  \" ,ent.text)"
      ],
      "metadata": {
        "id": "Ex6m3aM5qtKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762a7c2b-d853-4250-f63f-9cdab77482c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name   --->>>>   Keval Savaliya\n",
            "Location   --->>>>   Rajkot\n",
            "Years of Experience   --->>>>   360311\n",
            "\n",
            "College Name   --->>>>   Nirma University\n",
            "Degree   --->>>>   B.Tech Computer Science And Engineering\n",
            "College Name   --->>>>   Tapovan Science School\n",
            "Location   --->>>>   Rajkot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user MyMuPDF"
      ],
      "metadata": {
        "id": "S9V053o4_91W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, fitz"
      ],
      "metadata": {
        "id": "Ev3NjMa7AgKa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname='/content/CV-Parsing-using-Spacy-3/data/test/Smith Resume.pdf'\n",
        "doc-fitz.open(fname)"
      ],
      "metadata": {
        "id": "5ngaEH0aAoUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=''\n",
        "for page in doc:\n",
        "  text=text+str(page.get_text())\n",
        "text"
      ],
      "metadata": {
        "id": "wKPL954nA3Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=text.strip()\n",
        "text"
      ],
      "metadata": {
        "id": "K2Cxdc9wBPFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\" \".join(text.split())\n",
        "text"
      ],
      "metadata": {
        "id": "nkXJroz6BZnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FdGYMjL9Bm3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a1aa7f-aa3e-4bc7-c955-60c8b6f0426b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIgbrBWr9QCf",
        "outputId": "dba2568b-9199-4770-c379-0e9522daff52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r dataset2.zip /content/CV-Parsing-using-Spacy-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVTkRJgq9Y8t",
        "outputId": "650c1ab4-76c7-4b11-db35-7d45803ac004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/CV-Parsing-using-Spacy-3/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/README.md (deflated 45%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/meta.json (deflated 39%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/ner/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/ner/cfg (deflated 49%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/ner/model (deflated 8%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/ner/moves (deflated 76%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/vocab/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/vocab/key2row (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/vocab/lookups.bin (deflated 45%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/vocab/vectors (deflated 45%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/vocab/lexemes.bin (deflated 72%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/vocab/strings.json (deflated 74%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/nlp_model/tokenizer (deflated 82%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/fsmonitor-watchman.sample (deflated 62%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/pre-push.sample (deflated 49%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/push-to-checkout.sample (deflated 55%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/config (deflated 31%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/refs/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/refs/heads/master (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/info/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/info/exclude (deflated 28%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/packed-refs (deflated 11%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/refs/remotes/origin/HEAD (deflated 26%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/refs/heads/master (deflated 26%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/logs/HEAD (deflated 26%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/index (deflated 44%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/branches/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/description (deflated 14%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/HEAD (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/objects/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/objects/pack/pack-41ffd17e88fcc83f0b1847bbbfa10e498f2a263e.pack (deflated 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/objects/pack/pack-41ffd17e88fcc83f0b1847bbbfa10e498f2a263e.idx (deflated 25%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/.git/objects/info/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/test/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/test/Smith Resume.docx (deflated 16%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/test/Alice Clark CV.pdf (deflated 7%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/test/Smith Resume.pdf (deflated 13%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/test/Alice Clark CV.txt (deflated 46%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/test/Alice Clark CV.docx (deflated 18%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/training/ (stored 0%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/training/config.cfg (deflated 62%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/training/base_config.cfg (deflated 56%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/training/train_data.pkl (deflated 66%)\n",
            "  adding: content/CV-Parsing-using-Spacy-3/data/training/train_data.json (deflated 88%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('dataset2.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5bbFo1cZ9lVY",
        "outputId": "888173c8-57ad-48c5-b5af-16ea84933b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0edd00ce-f108-4cbc-8c0c-73cd6f4b5343\", \"dataset2.zip\", 11577760)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}